{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://liquipedia.net/apexlegends/Portal:Teams/Americas'\n",
    "url2 = 'https://liquipedia.net/apexlegends/Portal:Teams/EMEA'\n",
    "url3 = 'https://liquipedia.net/apexlegends/Portal:Teams/APAC_North'\n",
    "url4 = 'https://liquipedia.net/apexlegends/Portal:Teams/APAC_South'\n",
    "url5 = 'https://liquipedia.net/apexlegends/Portal:Players'\n",
    "Headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.50','Referer': 'https://liquipedia.net/apexlegends/Portal:Teams','Accept-Language':'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',\n",
    "'Cookie':'_pk_id.1.4442=59e8dd207cfb54ed.1684816505.; _pbjs_userid_consent_data=3524755945110770; na-unifiedid={\"TDID\":\"b1ac3fcf-c7ec-4157-bb47-a7aaed02cbba\",\"TDID_LOOKUP\":\"FALSE\",\"TDID_CREATED_AT\":\"2023-05-23T04:35:14\"}; cto_bundle=xIvh9l9OaW1wQSUyQiUyQkxoM3Jvdng3S2NpWXd6ejBMWjh1bkEzdDdEV0tORlM0djJDdHR5em9OSkt2VlMlMkY0TW96cGVTWG9NWWpMJTJGY2xtR2l6NXBuRU5MQ3Z2VE5iNE4ycWlacUxXTmZXTHVRMXhaY0szbGpMSG0wdGtVJTJGandQNkJpdEViRUI; _pk_ref.1.4442=[\"\",\"\",1684826270,\"https://www.bing.com/\"]; _ga_3TE8DNE0DL=GS1.1.1684826270.2.0.1684826270.0.0.0; _ga=GA1.2.1380062086.1684816506'\n",
    "}\n",
    "response1 = requests.get(url=url1,headers=Headers)\n",
    "response2 = requests.get(url=url2,headers=Headers)\n",
    "response3 = requests.get(url=url3,headers=Headers)\n",
    "response4 = requests.get(url=url4,headers=Headers)\n",
    "response5 = requests.get(url=url5,headers=Headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取全球各赛区战队名称\n",
    "def getTeam(html):\n",
    "    team_list = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    team_list.append((soup.find('li',{'class':'active'})).find('a').string)\n",
    "    div = soup.find_all('span',{'class':'team-template-text'})\n",
    "\n",
    "    for li in div:\n",
    "        a = li.find('a')\n",
    "        text = a.string\n",
    "        team_list.append(text)\n",
    "        \n",
    "    return team_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取各战队所拥有队员ID\n",
    "def getplayerID(html):\n",
    "    Id = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    div = soup.find_all('span',style=\"white-space:pre\")\n",
    "\n",
    "    for li in div:\n",
    "        a = li.find('a')\n",
    "        text = a.string\n",
    "        Id.append(text)\n",
    "\n",
    "    return Id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取各战队所拥有队员真实姓名\n",
    "def getplayerName(html):\n",
    "    Real_Name = []\n",
    "    a = re.findall(r'<td>(.*?)</td>', html, re.I|re.M)\n",
    "\n",
    "    for li in a:\n",
    "        if li == \"\":\n",
    "            li = \"UNKNOWN\"\n",
    "        text = li\n",
    "        Real_Name.append(text)\n",
    "\n",
    "    return Real_Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取全球各赛区战队及其队员的信息\n",
    "csvf = open('Apex Legends Global Teams and Players.csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getTeam(response1.text))\n",
    "fw.writerow(getplayerID(response1.text))\n",
    "fw.writerow(getplayerName(response1.text))\n",
    "fw.writerow(getTeam(response2.text))\n",
    "fw.writerow(getplayerID(response2.text))\n",
    "fw.writerow(getplayerName(response2.text))\n",
    "fw.writerow(getTeam(response3.text))\n",
    "fw.writerow(getplayerID(response3.text))\n",
    "fw.writerow(getplayerName(response3.text))\n",
    "fw.writerow(getTeam(response4.text))\n",
    "fw.writerow(getplayerID(response4.text))\n",
    "fw.writerow(getplayerName(response4.text))\n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取个人价值排名前20的选手\n",
    "def getHighlightedPlayer(html):\n",
    "    HighlightedPlayer_list = []\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    div = soup.find_all('tr',style=\"line-height:25px\")\n",
    "    line = re.findall(r'<td><a[^>]*>(.*?)</a></td>', html, re.I|re.M)\n",
    "\n",
    "    for li in line:\n",
    "        HighlightedPlayer_list.append(li)\n",
    "\n",
    "    return(HighlightedPlayer_list)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取高价值选手的个人信息\n",
    "def getPlayerInf(html):\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    Information = []\n",
    "    for i in range(20):\n",
    "        HighlightedPlayer[i] = HighlightedPlayer[i].replace(' ','_')\n",
    "        url = 'https://liquipedia.net/apexlegends/'+HighlightedPlayer[i]\n",
    "        res = requests.get(url=url,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        div1 = soup.find_all('p')\n",
    "        a = div1[0].text\n",
    "        Information.append(a)\n",
    "        \n",
    "    return Information  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayerInf2(html):\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    Rank = []\n",
    "    for i in range(20):\n",
    "        HighlightedPlayer[i] = HighlightedPlayer[i].replace(' ','_')\n",
    "        url = 'https://liquipedia.net/apexlegends/'+HighlightedPlayer[i]\n",
    "        res = requests.get(url=url,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser') \n",
    "        div2 = soup.find_all('b',{'class':\"placement-text\"})\n",
    "        for li in div2:\n",
    "            text = li.string\n",
    "            Rank.append(text)    \n",
    "        \n",
    "    return Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayerInf3(html):\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    Match = []\n",
    "    for i in range(20):\n",
    "        HighlightedPlayer[i] = HighlightedPlayer[i].replace(' ','_')\n",
    "        url = 'https://liquipedia.net/apexlegends/'+HighlightedPlayer[i]\n",
    "        res = requests.get(url=url,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser') \n",
    "        div3 = soup.find_all('td',style=\"text-align:left\")\n",
    "        for li in div3:\n",
    "            a = li.find('a')\n",
    "            text = a\n",
    "            Match.append(text)     \n",
    "        \n",
    "    return Match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayerInf4(html):\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    Date = []\n",
    "    for i in range(20):\n",
    "        HighlightedPlayer[i] = HighlightedPlayer[i].replace(' ','_')\n",
    "        url = 'https://liquipedia.net/apexlegends/'+HighlightedPlayer[i]\n",
    "        res = requests.get(url=url,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser') \n",
    "        div3 = soup.find('div',{'class':\"table-responsive\"}).find('tbody').find_all('tr')\n",
    "        for li in div3:\n",
    "            a = li.find('td')\n",
    "            text = a\n",
    "            Date.append(text)\n",
    "\n",
    "    return Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取个人价值排名前20的选手的个人信息\n",
    "csvf = open('Top 20 Players in Apex Legends .csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getHighlightedPlayer(response5.text))\n",
    "fw.writerow(getPlayerInf(response5.text))\n",
    "fw.writerow(getPlayerInf4(response5.text))\n",
    "fw.writerow(getPlayerInf2(response5.text))\n",
    "fw.writerow(getPlayerInf3(response5.text))\n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/commons/images/thumb/1/1e/TSM_ImperialHal_at_the_ALGS_Stockholm_Playoffs.jpg/600px-TSM_ImperialHal_at_the_ALGS_Stockholm_Playoffs.jpg', '/commons/images/thumb/d/d2/TSM_Verhulst_at_the_ALGS_Stockholm_Playoffs.jpg/600px-TSM_Verhulst_at_the_ALGS_Stockholm_Playoffs.jpg', '/commons/images/thumb/b/bb/TSM_Reps_at_the_ALGS_Raleigh_Championship.jpg/600px-TSM_Reps_at_the_ALGS_Raleigh_Championship.jpg', '/commons/images/thumb/5/56/NRG_sweetdreams_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-NRG_sweetdreams_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/c/c2/NRG_Gild_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-NRG_Gild_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/7/78/NRG_nafen_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-NRG_nafen_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/1/1d/Acend_PostKiLL_at_the_ALGS_2022_Championship.jpg/600px-Acend_PostKiLL_at_the_ALGS_2022_Championship.jpg', '/commons/images/thumb/f/fc/Acend_Lufka_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Acend_Lufka_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/5/56/Acend_k4shera_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Acend_k4shera_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/4/4e/XSET_FunFPS_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-XSET_FunFPS_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/9/93/XSET_Sikezz_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-XSET_Sikezz_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/7/7c/Alliance_Hakis_at_the_ALGS_Raleigh_Championship.jpg/600px-Alliance_Hakis_at_the_ALGS_Raleigh_Championship.jpg', '/commons/images/thumb/e/e0/Alliance_Yuki_at_the_ALGS_Raleigh_Championship.jpg/600px-Alliance_Yuki_at_the_ALGS_Raleigh_Championship.jpg', '/commons/images/thumb/2/28/XSET_oh_Nocturnal_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-XSET_oh_Nocturnal_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/5/59/SCARZ_Mande_at_the_ALGS_Raleigh_Championship.jpg/600px-SCARZ_Mande_at_the_ALGS_Raleigh_Championship.jpg', '/commons/images/thumb/3/31/Moist_Wxltzy_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Moist_Wxltzy_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/5/58/Luminosity_YanYa_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Luminosity_YanYa_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/f/f0/Moist_Emtee_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Moist_Emtee_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/3/3c/Moist_Prycyy_at_the_ALGS_London_Split_1_Playoffs.jpg/600px-Moist_Prycyy_at_the_ALGS_London_Split_1_Playoffs.jpg', '/commons/images/thumb/0/0d/G2_Dezignful.png/600px-G2_Dezignful.png']\n"
     ]
    }
   ],
   "source": [
    "def getsrc(html):\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    src = []\n",
    "    for i in range(20):\n",
    "        HighlightedPlayer[i] = HighlightedPlayer[i].replace(' ','_')\n",
    "        url = 'https://liquipedia.net/apexlegends/'+HighlightedPlayer[i]\n",
    "        res = requests.get(url=url,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        divp = soup.find('a',{'class':'image'}).find('img').get('src')\n",
    "        src.append(divp)\n",
    "    return src\n",
    "print(getsrc(response5.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取个人价值前20名选手的照片\n",
    "def getPictures(url,path):\n",
    "    res = requests.get(url=url,headers=Headers)\n",
    "    with open(path,'wb')as f:\n",
    "        for chunk in res.iter_content(chunk_size=128):\n",
    "            f.write(chunk)\n",
    "\n",
    "def getTop20PlayerPictures(html):\n",
    "    src_list = getsrc(html)\n",
    "    HighlightedPlayer = getHighlightedPlayer(html)\n",
    "    for i in range(20):\n",
    "        urlp = 'https://liquipedia.net'+src_list[i]\n",
    "        path = HighlightedPlayer[i]+'.jpg'\n",
    "        getPictures(urlp,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTop20PlayerPictures(response5.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取2019-2023年Top50的战队及队员的近年数据\n",
    "def getTeamData():\n",
    "    TeamData = []\n",
    "    for i in range(2019,2024):\n",
    "        urldata = 'https://liquipedia.net/apexlegends/Portal:Statistics/{}'.format(i)\n",
    "        res = requests.get(url=urldata,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        divt = soup.find_all('div',{'class':\"divRow\"})\n",
    "        \n",
    "        for li in divt:\n",
    "            team = li.find('span',{'class':\"team-template-text\"}).find('a')\n",
    "            _1st = li.find_all('div',{'class':\"divCell\"})[2].text \n",
    "            _2nd = li.find_all('div',{'class':\"divCell\"})[3].text\n",
    "            _3rd_4th = li.find_all('div',{'class':\"divCell\"})[4].text\n",
    "            Totalwinnings = li.find_all('div',{'class':\"divCell\"})[5].text\n",
    "            TeamData.append(team.string+\" owns [\"+_1st+\" 1st] [\"+_2nd+\" 2nd] [\"+_3rd_4th+\" 3rd/4th] [\"+Totalwinnings+\" Totalwinnings]\") \n",
    "    \n",
    "    return TeamData\n",
    "\n",
    "def getPlayerData():\n",
    "    PlayerData = []\n",
    "    for i in range(2019,2024):\n",
    "        urldata = 'https://liquipedia.net/apexlegends/Portal:Statistics/{}'.format(i)\n",
    "        res = requests.get(url=urldata,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        divp = soup.find_all('tr',style=\"line-height:25px\")\n",
    "\n",
    "        for li in divp:\n",
    "            player = li.find_all('td')[1].find('a')\n",
    "            _1st = li.find_all('td',style=\"text-align:center\")[0].text \n",
    "            _2nd = li.find_all('td',style=\"text-align:center\")[1].text\n",
    "            _3rd_4th = li.find_all('td',style=\"text-align:center\")[2].text\n",
    "            _S_Tier = li.find_all('td',style=\"text-align:center\")[3].text\n",
    "            Earnings = li.find_all('td')[6].string\n",
    "            PlayerData.append(player.string+\" owns [\"+_1st+\" 1st] [\"+_2nd+\" 2nd] [\"+_3rd_4th+\" 3rd/4th] [\"+_S_Tier+\" S-Tier] [\"+Earnings+\" Earnings]\")    \n",
    "    \n",
    "    return PlayerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvf = open('2019-2023 Team Statics .csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getTeamData())\n",
    "csvf.close()\n",
    "\n",
    "csvf = open('2019-2023 Player Statics .csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getPlayerData())\n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取所有队伍与选手信息\n",
    "def getTeamOverall():\n",
    "    TeamOverall = []\n",
    "    urldata = 'https://liquipedia.net/apexlegends/Portal:Statistics/Team_earnings'\n",
    "    res = requests.get(url=urldata,headers=Headers)\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    divt = soup.find('div',{'class':\"mw-parser-output\"}).find('tbody').find_all('tr')\n",
    "    i = 0    \n",
    "\n",
    "    for li in divt:\n",
    "        if i != 0:\n",
    "            team = li.find('span',{'class':\"team-template-text\"}).find('a').string\n",
    "            _1st = li.find_all('td',style=\"text-align:center\")[0].text \n",
    "            _2nd = li.find_all('td',style=\"text-align:center\")[1].text \n",
    "            _3rd_4th = li.find_all('td',style=\"text-align:center\")[2].text \n",
    "            _S_Tier = li.find_all('td',style=\"text-align:center\")[3].text\n",
    "            Totalwinnings = li.find_all('td')[5].text\n",
    "            TeamOverall.append(team+\" owns [\"+_1st+\" 1st] [\"+_2nd+\" 2nd] [\"+_3rd_4th+\" 3rd/4th] [\"+_S_Tier+\" S-Tier] [\"+Totalwinnings+\" Totalwinnings]\") \n",
    "        i += 1\n",
    "  \n",
    "    return TeamOverall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayerOverall():\n",
    "    PlayerOverall = []\n",
    "    for i in range(2019,2024):\n",
    "        urldata = 'https://liquipedia.net/apexlegends/Portal:Statistics/Player_earnings'\n",
    "        res = requests.get(url=urldata,headers=Headers)\n",
    "        soup = BeautifulSoup(res.text,'html.parser')\n",
    "        divp = soup.find_all('tr',style=\"line-height:25px\")\n",
    "\n",
    "        for li in divp:\n",
    "            player = li.find_all('td')[1].find('a')\n",
    "            _1st = li.find_all('td',style=\"text-align:center\")[0].text \n",
    "            _2nd = li.find_all('td',style=\"text-align:center\")[1].text\n",
    "            _3rd_4th = li.find_all('td',style=\"text-align:center\")[2].text\n",
    "            _S_Tier = li.find_all('td',style=\"text-align:center\")[3].text\n",
    "            Earnings = li.find_all('td')[6].string\n",
    "            PlayerOverall.append(player.string+\" owns [\"+_1st+\" 1st] [\"+_2nd+\" 2nd] [\"+_3rd_4th+\" 3rd/4th] [\"+_S_Tier+\" S-Tier] [\"+Earnings+\" Earnings]\")    \n",
    "    \n",
    "    return PlayerOverall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取最年轻以及最年长的选手\n",
    "def getAge():\n",
    "    Youngest = []\n",
    "    Oldest = []\n",
    "    urldata = 'https://liquipedia.net/apexlegends/Portal:Statistics'\n",
    "    res = requests.get(url=urldata,headers=Headers)\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    divy = soup.find_all('table',{'class':\"wikitable smwtable jquery-tablesorter sortable\"},style=\"margin-left:0px;margin-right:auto\")\n",
    "    i = 0\n",
    "    for li2 in divy:\n",
    "        divo = li2.find('tbody').find_all('tr')\n",
    "        for li in divo:\n",
    "            if i != 0  and i <= 20:\n",
    "                id = li.find('b').find('a').string\n",
    "                age = li.find_all('td')[2].text\n",
    "                Youngest.append(id + \" \" + age)\n",
    "            elif i > 20 and i != 21:\n",
    "                id = li.find('b').find('a').string\n",
    "                age = li.find_all('td')[2].text\n",
    "                Oldest.append(id + \" \" + age)\n",
    "            i += 1\n",
    "    return Youngest,Oldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvf = open('TeamOverall.csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getTeamOverall())\n",
    "csvf.close()\n",
    "\n",
    "csvf = open('PlayerOverall.csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getPlayerOverall())\n",
    "csvf.close()\n",
    "\n",
    "csvf = open('PlayerAge.csv','w',encoding='utf-8')\n",
    "fw = csv.writer(csvf)\n",
    "fw.writerow(getAge())\n",
    "csvf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
